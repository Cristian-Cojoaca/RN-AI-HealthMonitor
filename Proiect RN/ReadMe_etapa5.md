# ğŸ“˜ README â€“ Etapa 5: Configurarea È™i Antrenarea Modelului RN

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** [Cojoaca Cristian]  
**Link Repository GitHub:** [URL complet]  
**Data predÄƒrii:** [Data]

---

CompletaÈ›i **TOATE** punctele urmÄƒtoare:

1. **Antrenare model** definit Ã®n Etapa 4 pe setul final de date (â‰¥40% originale)
2. **Minimum 10 epoci**, batch size 8â€“32
3. **ÃmpÄƒrÈ›ire stratificatÄƒ** train/validation/test: 70% / 15% / 15%
4. **Tabel justificare hiperparametri** (vezi secÈ›iunea de mai jos - OBLIGATORIU)
5. **Metrici calculate pe test set:**
   - **AcurateÈ›e â‰¥ 65%**
   - **F1-score (macro) â‰¥ 0.60**
6. **Salvare model antrenat** Ã®n `models/trained_model.h5` (Keras/TensorFlow) sau `.pt` (PyTorch) sau `.lvmodel` (LabVIEW)
7. **Integrare Ã®n UI din Etapa 4:**
   - UI trebuie sÄƒ Ã®ncarce modelul ANTRENAT (nu dummy)
   - InferenÈ›Äƒ REALÄ‚ demonstratÄƒ
   - Screenshot Ã®n `docs/screenshots/inference_real.png`

   **Hiperparametru** | **Valoare AleasÄƒ** | **Justificare** |
|--------------------|-------------------|-----------------|
| Learning rate | Ex: 0.001 | Valoare standard pentru Adam optimizer, asigurÄƒ convergenÈ›Äƒ stabilÄƒ |
| Batch size | Ex: 32 | Compromis memorie/stabilitate pentru N=[8661] samples |
| Number of epochs | Ex: 50 | Cu early stopping dupÄƒ 10 epoci fÄƒrÄƒ Ã®mbunÄƒtÄƒÈ›ire |
| Optimizer | Ex: Adam | Adaptive learning rate, potrivit pentru RN cu [numÄƒrul vostru] straturi |
| Loss function | Ex: Categorical Crossentropy | Clasificare multi-class cu K=[numÄƒrul vostru] clase |
| Activation functions | Ex: ReLU (hidden), Softmax (output) | ReLU pentru non-linearitate, Softmax pentru probabilitÄƒÈ›i clase |